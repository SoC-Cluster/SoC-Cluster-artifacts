# Deep Learning Inference Energy Efficiency

This benchmark targets deep learning (DL) inference energy efficiency with varying input loads on NVIDIA GPU (NVIDIA A100), and SoC GPU.

Used models: ResNet-50 and YOLOv5x.

- NVIDIA GPU: [doc](./nvidia_gpu/README.md)
- SoC GPU: [doc](./soc_cluster/README.md)